{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sobre o Projeto e Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicadores\n",
    "\n",
    "Com base no dicionário de dados fornecido pela Passos Mágicos, ficou definido que os seguintes indicadores serão utilizados:\n",
    "\n",
    "### **1. Desempenho em Disciplinas Específicas**  \n",
    "- **Dados necessários:** `NOTA_PORT`, `NOTA_MAT`, `NOTA_ING`.  \n",
    "- **Descrição:** Médias de notas em disciplinas específicas, como português, matemática e inglês.\n",
    "\n",
    "### **2. Frequência Escolar e Engajamento**  \n",
    "- **Dados necessários:** `FASE`, `TURMA`.  \n",
    "- **Descrição:** Dados sobre a fase e turma dos alunos, que podem ser utilizados para medir frequência e engajamento ao longo dos anos.\n",
    "\n",
    "### **3. Indicador de Desempenho Acadêmico (INDE)**  \n",
    "- **Dados necessários:** `INDE`.  \n",
    "- **Descrição:** O Índice do Desenvolvimento Educacional (INDE) é uma métrica que combina outros indicadores (IAN, IDA, IEG, IAA, IPS, IPP e IPV) para avaliar o desempenho acadêmico geral dos alunos ao longo dos anos.\n",
    "\n",
    "### **4. Indicador de Aprendizagem (IDA)**  \n",
    "- **Dados necessários:** `IDA`.  \n",
    "- **Descrição:** Média das notas do indicador de aprendizagem, medindo o progresso acadêmico dos alunos.\n",
    "\n",
    "### **5. Indicador de Engajamento (IEG)**  \n",
    "- **Dados necessários:** `IEG`.  \n",
    "- **Descrição:** Média das notas de engajamento dos alunos, mensurando a participação e envolvimento deles nas atividades.\n",
    "\n",
    "### **6. Indicador Psicossocial (IPS)**  \n",
    "- **Dados necessários:** `IPS`.  \n",
    "- **Descrição:** Média das notas psicossociais dos alunos, avaliando seu bem-estar emocional e social.\n",
    "\n",
    "### **7. Indicador Psicopedagógico (IPP)**  \n",
    "- **Dados necessários:** `IPP`.  \n",
    "- **Descrição:** Média das notas psicopedagógicas dos alunos, refletindo o suporte que receberam nesse aspecto.\n",
    "\n",
    "### **8. Indicador de Autoavaliação (IAA)**  \n",
    "- **Dados necessários:** `IAA`.  \n",
    "- **Descrição:** Média das notas de autoavaliação dos alunos, que refletem sua percepção de progresso.\n",
    "\n",
    "### **9. Indicador de Ponto de Virada (IPV)**  \n",
    "- **Dados necessários:** `IPV`.  \n",
    "- **Descrição:** Média das notas que indicam o \"ponto de virada\" — um momento de mudança significativa no desempenho ou comportamento do aluno.\n",
    "\n",
    "### **10. Classificação de Desempenho (Pedra)**  \n",
    "- **Dados necessários:** `PEDRA`.  \n",
    "- **Descrição:** Classificação dos alunos com base no seu INDE, em níveis como Quartzo, Ágata, Ametista e Topázio.\n",
    "\n",
    "### **11. Recomendações Psicopedagógicas**  \n",
    "- **Dados necessários:** `REC_PSICO`.  \n",
    "- **Descrição:** Recomendações feitas pela equipe psicopedagógica para acompanhamento e suporte ao aluno.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 Tabela de Indicadores Sugeridos  \n",
    "\n",
    "| Nome do Campo             | Descrição                                                                                                                                       | Tipo de Dados |\n",
    "|---------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------|---------------|\n",
    "| `NOTA_PORT`, `NOTA_MAT`, `NOTA_ING` | Médias de notas em disciplinas específicas, como português, matemática e inglês.                                                            | Numérico      |\n",
    "| `FASE`, `TURMA`           | Dados sobre a fase e turma dos alunos, que podem ser utilizados para medir frequência e engajamento ao longo dos anos.                            | Texto         |\n",
    "| `INDE`                    | O Índice do Desenvolvimento Educacional (INDE) é uma métrica que combina outros indicadores (IAN, IDA, IEG, IAA, IPS, IPP e IPV) para avaliar o desempenho acadêmico geral dos alunos ao longo dos anos. | Numérico      |\n",
    "| `IDA`                     | Média das notas do indicador de aprendizagem, medindo o progresso acadêmico dos alunos.                                                          | Numérico      |\n",
    "| `IEG`                     | Média das notas de engajamento dos alunos, mensurando a participação e envolvimento deles nas atividades.                                        | Numérico      |\n",
    "| `IPS`                     | Média das notas psicossociais dos alunos, avaliando seu bem-estar emocional e social.                                                            | Numérico      |\n",
    "| `IPP`                     | Média das notas psicopedagógicas dos alunos, refletindo o suporte que receberam nesse aspecto.                                                   | Numérico      |\n",
    "| `IAA`                     | Média das notas de autoavaliação dos alunos, que refletem sua percepção de progresso.                                                            | Numérico      |\n",
    "| `IPV`                     | Média das notas que indicam o \"ponto de virada\" — um momento de mudança significativa no desempenho ou comportamento do aluno.                    | Numérico      |\n",
    "| `PEDRA`                   | Classificação dos alunos com base no seu INDE, em níveis como Quartzo, Ágata, Ametista e Topázio.                                                | Texto         |\n",
    "| `REC_PSICO`               | Recomendações feitas pela equipe psicopedagógica para acompanhamento e suporte ao aluno.                                                          | Texto         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Análise e Desenvolvimento do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install pyspark\n",
    "# %pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importação das bibliotecas que serão utilizadas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparkPostgres:\n",
    "    def __init__(self, spark, host, port, database, user, password, schema=None):\n",
    "        self.spark = spark\n",
    "        self.url = f\"jdbc:postgresql://{host}:{port}/{database}\"\n",
    "        self.schema = schema\n",
    "        self.properties = {\n",
    "            \"user\": user,\n",
    "            \"password\": password,\n",
    "            \"driver\": \"org.postgresql.Driver\"\n",
    "        }\n",
    "\n",
    "    def read(self, table):\n",
    "        # Adiciona o esquema, se definido\n",
    "        full_table = f\"{self.schema}.{table}\" if self.schema else table\n",
    "        return self.spark.read.jdbc(url=self.url, table=full_table, properties=self.properties)\n",
    "\n",
    "    def create_temp_view(self, sql_query, view_name):\n",
    "        # Inclui o esquema em tabelas na consulta SQL\n",
    "        if self.schema:\n",
    "            sql_query = self._add_schema_to_query(sql_query)\n",
    "\n",
    "        df = self.spark.read.jdbc(url=self.url, table=f\"({sql_query}) as tmp\", properties=self.properties)\n",
    "        df.createOrReplaceTempView(view_name)\n",
    "        return df\n",
    "\n",
    "    def _add_schema_to_query(self, sql_query):\n",
    "        \"\"\"Adiciona o esquema a todas as tabelas da consulta SQL.\"\"\"\n",
    "        # Substitui nomes de tabela simples pelo esquema e tabela, assumindo que não há alias complexos\n",
    "        import re\n",
    "        pattern = r'\\bFROM\\s+(\\w+)'\n",
    "        return re.sub(pattern, fr'FROM {self.schema}.\\1', sql_query, flags=re.IGNORECASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"CSV to PostgreSQL\").getOrCreate()\n",
    "\n",
    "host = os.getenv(\"DB_HOST\")\n",
    "port = os.getenv(\"DB_PORT\")\n",
    "database = os.getenv(\"DB_DATABASE\")\n",
    "user = os.getenv(\"DB_USER\")\n",
    "password = os.getenv(\"DB_PASSWORD\")\n",
    "schema = os.getenv(\"DB_SCHEMA\")\n",
    "\n",
    "spark_postgres = SparkPostgres(spark, host, port, database, user, password, schema)\n",
    "\n",
    "sql_query = \"\"\"\n",
    "SELECT\n",
    "    CAST(nome AS TEXT) AS nome,\n",
    "    CAST(instituicao_ensino_aluno AS TEXT) AS instituicao_ensino_aluno,\n",
    "    CAST(idade_aluno AS TEXT) AS idade_aluno,\n",
    "    CAST(anos_pm AS TEXT) AS anos_pm,\n",
    "    CAST(fase_turma AS TEXT) AS fase,\n",
    "    CAST(ponto_virada AS TEXT) AS ponto_virada,\n",
    "    CAST(inde AS TEXT) AS inde,\n",
    "    CAST(inde_conceito AS TEXT) AS inde_conceito,\n",
    "    CAST(pedra AS TEXT) AS pedra,\n",
    "    CAST(destaque_ieg AS TEXT) AS destaque_ieg,\n",
    "    CAST(destaque_ida AS TEXT) AS destaque_ida,\n",
    "    CAST(destaque_ipv AS TEXT) AS destaque_ipv,\n",
    "    CAST(iaa AS TEXT) AS iaa,\n",
    "    CAST(ieg AS TEXT) AS ieg,\n",
    "    CAST(ips AS TEXT) AS ips,\n",
    "    CAST(ida AS TEXT) AS ida,\n",
    "    CAST(ipp AS TEXT) AS ipp,\n",
    "    CAST(ipv AS TEXT) AS ipv,\n",
    "    CAST(ian AS TEXT) AS ian,\n",
    "    CAST(ano AS TEXT) AS ano,\n",
    "    CAST(dt_pst AS TEXT) AS dt_pst\n",
    "FROM\n",
    "    tb_dados_principais_2020\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT\n",
    "    CAST(nome AS TEXT) AS nome,\n",
    "    CAST(instituicao_ensino_aluno AS TEXT) AS instituicao_ensino_aluno,\n",
    "    CAST(NULL AS TEXT) AS idade_aluno,\n",
    "    CAST(NULL AS TEXT) AS anos_pm,\n",
    "    CAST(fase AS TEXT) AS fase,\n",
    "    CAST(ponto_virada AS TEXT) AS ponto_virada,\n",
    "    CAST(inde AS TEXT) AS inde,\n",
    "    CAST(NULL AS TEXT) AS inde_conceito,\n",
    "    CAST(pedra AS TEXT) AS pedra,\n",
    "    CAST(NULL AS TEXT) AS destaque_ieg,\n",
    "    CAST(NULL AS TEXT) AS destaque_ida,\n",
    "    CAST(NULL AS TEXT) AS destaque_ipv,\n",
    "    CAST(iaa AS TEXT) AS iaa,\n",
    "    CAST(ieg AS TEXT) AS ieg,\n",
    "    CAST(ips AS TEXT) AS ips,\n",
    "    CAST(ida AS TEXT) AS ida,\n",
    "    CAST(ipp AS TEXT) AS ipp,\n",
    "    CAST(ipv AS TEXT) AS ipv,\n",
    "    CAST(ian AS TEXT) AS ian,\n",
    "    CAST(ano AS TEXT) AS ano,\n",
    "    CAST(dt_pst AS TEXT) AS dt_pst\n",
    "FROM\n",
    "    tb_dados_principais_2021\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT\n",
    "    CAST(nome AS TEXT) AS nome,\n",
    "    CAST(NULL AS TEXT) AS instituicao_ensino_aluno,\n",
    "    CAST(NULL AS TEXT) AS idade_aluno,\n",
    "    CAST(NULL AS TEXT) AS anos_pm,\n",
    "    CAST(fase AS TEXT) AS fase,\n",
    "    CAST(ponto_virada AS TEXT) AS ponto_virada,\n",
    "    CAST(inde AS TEXT) AS inde,\n",
    "    CAST(NULL AS TEXT) AS inde_conceito,\n",
    "    CAST(pedra AS TEXT) AS pedra,\n",
    "    CAST(destaque_ieg AS TEXT) AS destaque_ieg,\n",
    "    CAST(destaque_ida AS TEXT) AS destaque_ida,\n",
    "    CAST(destaque_ipv AS TEXT) AS destaque_ipv,\n",
    "    CAST(iaa AS TEXT) AS iaa,\n",
    "    CAST(ieg AS TEXT) AS ieg,\n",
    "    CAST(ips AS TEXT) AS ips,\n",
    "    CAST(ida AS TEXT) AS ida,\n",
    "    CAST(ipp AS TEXT) AS ipp,\n",
    "    CAST(ipv AS TEXT) AS ipv,\n",
    "    CAST(ian AS TEXT) AS ian,\n",
    "    CAST(ano AS TEXT) AS ano,\n",
    "    CAST(dt_pst AS TEXT) AS dt_pst\n",
    "FROM\n",
    "    tb_dados_principais_2022\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "df_dados_principais_spark = spark_postgres.create_temp_view(sql_query, \"tb_dados_principais\")\n",
    "df_aluno_spark = spark_postgres.read(\"tb_aluno_mrg\")\n",
    "df_historico_spark = spark_postgres.read(\"tb_historico_mrg\")\n",
    "df_fase_spark = spark_postgres.read(\"tb_fase_mrg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/09 18:34:21 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# df_dados_principais_spark.write.format(\"csv\").option(\"header\", \"true\").save(\"dados_principais\")\n",
    "df_aluno_spark.write.format(\"csv\").option(\"header\", \"true\").save(\"aluno\")\n",
    "df_historico_spark.write.format(\"csv\").option(\"header\", \"true\").save(\"historico\")\n",
    "df_fase_spark.write.format(\"csv\").option(\"header\", \"true\").save(\"fase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados_principais = df_dados_principais_spark.toPandas()\n",
    "df_aluno = df_aluno_spark.toPandas()\n",
    "df_historico = df_historico_spark.toPandas()\n",
    "df_fase = df_fase_spark.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pm = pd.read_csv('bases_e_documental\\pede_passos_dataset_fiap.csv', sep=';')\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alunos = pd.read_csv('bases_e_documental/Base de dados - Passos Mágicos/TbAluno/Merge/merged_data.csv', sep=',')\n",
    "df_fase = pd.read_csv('bases_e_documental/Base de dados - Passos Mágicos/TbFase/Merge/merged_data.csv', sep=',')\n",
    "df_historico = pd.read_csv('bases_e_documental\\Base de dados - Passos Mágicos\\TbHistorico\\Merge\\merged_data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificar se os três dataframes tem o IdAluno, para que possa ser utilizado como referência no merge\n",
    "print('IdAluno' in df_alunos.columns)\n",
    "print('IdAluno' in df_fase.columns)\n",
    "print('IdAluno' in df_historico.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# junta os 3 dataframes em um só\n",
    "# Realizar o merge dos DataFrames usando 'IdAluno' como referência\n",
    "df_merged = df_alunos.merge(df_fase, on='IdAluno', how='left')\n",
    "df_merged = df_merged.merge(df_historico, on='IdAluno', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.info(verbose=True, buf=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifica porcentagem de dados nulos por coluna\n",
    "df_merged.isnull().sum()/df_merged.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faz o drop da coluna, se 100% dos valores da coluna estiverem nulos\n",
    "# identifica colunas com 100% de valores nulos\n",
    "colunas_para_deletar = df_merged.columns[df_merged.isnull().all()]\n",
    "\n",
    "# converte objeto para uma lista\n",
    "colunas_para_deletar_lista = colunas_para_deletar.tolist()\n",
    "\n",
    "# criar um DataFrame para exibir a lista\n",
    "df_colunas_para_deletar = pd.DataFrame(colunas_para_deletar_lista, columns=['Colunas para Deletar'])\n",
    "\n",
    "# adiciona uma linha com o total de colunas deletadas\n",
    "total_deletadas = len(colunas_para_deletar_lista)\n",
    "df_colunas_para_deletar.loc['Total'] = [f'Total de colunas deletadas: {total_deletadas}']\n",
    "\n",
    "# exibe o DataFrame resultante\n",
    "df_colunas_para_deletar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleta as colunas identificadas\n",
    "df_merged.drop(columns=colunas_para_deletar, inplace=True)\n",
    "\n",
    "# Exibir o DataFrame atualizado\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra dataframe inteiro, sem truncar informações\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# altera informações da coluna IdTipoResponsável para facilitar a visualização\n",
    "df_merged['IdTipoResponsavel'] = df_merged['IdTipoResponsavel'].replace({1 : 'Pai', 2 : 'Mãe', 3 : 'O Próprio', 4 : 'Outros', 5 : 'Tia', 6 : 'Padrasto', 7 : 'Madrasta', 8 : 'Avó', 9 : 'Avô', 10 : 'Tio', 11 : 'Não definido', 12 : 'Outros Responsáveis', 13 : 'Mãe', 14 : 'Irmão', 15 : 'IRM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contagem de valores de uma coluna\n",
    "df_merged['IdTipoResponsavel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# altera informações da coluna Sexo para facilitar a visualização\n",
    "df_merged['Sexo'] = df_merged['Sexo'].replace({'F': 'Feminino', 'M': 'Masculino'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# altera informações da coluna CoraRaca para facilitar a visualização\n",
    "df_merged['CorRaca'] = df_merged['CorRaca'].replace({'B': 'Branca', 'P': 'Preta', 'R': 'Não especificado'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifica porcentagem de dados nulos por coluna\n",
    "df_merged.isnull().sum()/df_merged.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop em colunas que possuem menos de 100% do total de valores nulos - analisado caso - a - caso antes da deleção\n",
    "df_merged.drop(columns=['IdUsuarioEfetivacaoMatricula', 'ProblemaAutorizadoMatricula', 'IdUsuarioAutorizacaoMatricula', 'IdMotivoInativacao', 'IdDisciplina', 'StDependencia', 'NotaFinal', 'IdHistoricoNotas', 'StUsaCargaHorariaAnualHoraMinutoTexto', 'IdEstabelecimentoEnsino', 'StUsaCargaHorariaTotalHoraMinutoTexto', 'StCHIgnorarSoma_x', 'StCHIgnorarSoma_y'], inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma colunas object do dataframe em datetime\n",
    "columns = ['Data', 'DataOcorrencia_x', 'DataInclusao', 'DataSituacaoAtivo', 'DataSituacaoInativo', 'DataHoraEfetivacaoMatricula', 'DataNascimento', 'DataOcorrencia_y']\n",
    "df_merged[columns] = df_merged[columns].apply(pd.to_datetime, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certifica que as colunas são do tipo datetime\n",
    "df_merged['DataNascimento'] = pd.to_datetime(df_merged['DataNascimento'], errors='coerce')\n",
    "df_merged['DataInclusao'] = pd.to_datetime(df_merged['DataInclusao'], errors='coerce')\n",
    "df_merged['DataHoraEfetivacaoMatricula'] = pd.to_datetime(df_merged['DataHoraEfetivacaoMatricula'], errors='coerce')\n",
    "df_merged['DataOcorrencia_y'] = pd.to_datetime(df_merged['DataOcorrencia_y'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma colunas datetime em data, sem horário\n",
    "df_merged[['DataNascimento', 'DataInclusao', 'DataHoraEfetivacaoMatricula', 'DataOcorrencia_y']] = df_merged[['DataNascimento', 'DataInclusao', 'DataHoraEfetivacaoMatricula', 'DataOcorrencia_y']].apply(lambda x: x.dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.info(verbose=True, buf=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# contagem de valores nulos\n",
    "null_values = df_merged.isnull().sum()\n",
    "\n",
    "# calores únicos em cada coluna\n",
    "unique_values = df_merged.nunique()\n",
    "\n",
    "# análise descritiva básica\n",
    "desc_stats = df_merged.describe(include='all')\n",
    "\n",
    "# exibir as análises descritivas, contagem de valores nulos e valores únicos\n",
    "null_values, unique_values, desc_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Contagem de Valores Nulos\n",
    "\n",
    "A contagem de valores nulos nas principais colunas identificou um número significativo de valores faltantes em várias colunas importantes, incluindo:\n",
    "\n",
    "- `QuantidadeFaltasAnual`, `ResultadoFinal_x`, `CodigoSerie_y`, e `AnoConclusao_y`: Todas apresentam cerca de 32.714 valores nulos em 49.089 registros.\n",
    "\n",
    "- Isso representa quase 67% de valores nulos nessas colunas, o que é um ponto crítico que pode comprometer as análises de desempenho, engajamento e progresso acadêmico.\n",
    "\n",
    "**Implicações:**\n",
    "\n",
    "- `QuantidadeFaltasAnual`, `ResultadoFinal_x`, `CodigoSerie_y`, e `AnoConclusao_y`: Todas apresentam cerca de 32.714 valores nulos em 49.089 registros.\n",
    "\n",
    "- Isso representa quase 67% de valores nulos nessas colunas, o que é um ponto crítico que pode comprometer as análises de desempenho, engajamento e progresso acadêmico.\n",
    "\n",
    "## 3.2 Valores Únicos\n",
    "\n",
    "Algumas colunas possuem valores extremamente repetitivos ou até únicos:\n",
    "\n",
    "- **`ResultadoFinal_x`, `CodigoSerie_y`, e `AnoConclusao_y`**: Cada um desses campos tem apenas um valor único em todos os registros.\n",
    "\n",
    "- Para `ResultadoFinal_x`, todos os registros disponíveis estão marcados como \"Aprovado\". Isso levanta dúvidas sobre a integridade ou completude dos dados.\n",
    "\n",
    "**Implicações:**\n",
    "\n",
    "- **Dados de resultados limitados:** Com um único valor \"Aprovado\" para todos os registros, fica impossível distinguir entre alunos que passaram ou falharam. Isso sugere que há uma falta de dados sobre alunos que não tiveram bom desempenho.\n",
    "\n",
    "- **Falta de variabilidade em séries e anos de conclusão:** Isso impede uma análise longitudinal, ou seja, uma análise que verifique melhorias ou mudanças ao longo do tempo. Se todos os alunos estão no mesmo ano ou série, é difícil entender se há um progresso significativo.\n",
    "\n",
    "## 3.3 Análise Descritiva\n",
    "\n",
    "A função `describe()` fornece algumas estatísticas básicas sobre a distribuição dos dados:\n",
    "\n",
    "- **`IdAlunoRotinaEducacaoInfantil` e `IdAluno`**: O número de alunos é relativamente pequeno em comparação com o total de registros (49.089), o que indica que os mesmos alunos aparecem várias vezes.\n",
    "\n",
    "- **Faltas Anuais**: A média registrada é zero, o que reforça a ausência de dados de faltas, sendo uma área de grande preocupação.\n",
    "\n",
    "**Implicações:**\n",
    "\n",
    "- **Dados repetidos por aluno:** O fato de que um pequeno número de alunos aparece repetidamente sugere que estamos lidando com dados de múltiplas observações por aluno (provavelmente ao longo do tempo ou em diferentes turmas), o que seria normal em um acompanhamento contínuo. No entanto, seria necessário limpar e organizar os dados para focar nas métricas mais significativas por aluno.\n",
    "\n",
    "- **Faltas não registradas:** Com uma média de faltas igual a zero, conclui-se que os dados de frequência são ineficazes para análises que dependem de engajamento ou presença dos alunos.\n",
    "\n",
    "## 3.4 Pontos de Atenção\n",
    "\n",
    "- **Preenchimento de valores nulos:** A base de dados deve ser revisada para preencher os valores nulos ou lidar com eles de forma apropriada. Dependendo da disponibilidade de dados, pode ser necessário estimar alguns desses valores ou remover registros incompletos.\n",
    "\n",
    "- **Registro de faltas e resultados finais:** Há uma necessidade crítica de melhorar o registro de informações sobre faltas e desempenho acadêmico. Sem essas informações, será impossível medir adequadamente o progresso dos alunos e o impacto da ONG.\n",
    "\n",
    "- **Variabilidade dos dados:** A falta de variabilidade em dados importantes, como os resultados finais e séries, limita qualquer análise significativa. Será importante diversificar os dados coletados, especialmente em termos de resultados de alunos.\n",
    "\n",
    "## 3.5 Recomendações para Melhorar a Análise\n",
    "\n",
    "- **Revisar a coleta de dados**: É necessário garantir que todos os alunos tenham seus resultados finais e faltas registrados corretamente.\n",
    "\n",
    "- **Tratar os dados ausentes**: Colunas com muitos valores nulos precisam ser preenchidas (se possível) ou desconsideradas caso estejam comprometendo as análises.\n",
    "\n",
    "- **Analisar alunos individualmente**: Dado que existem múltiplos registros por aluno, seria útil realizar uma análise focada em cada aluno individualmente, para evitar a distorção causada por múltiplos registros que, talvez, não acrescentem valor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Representação Visual dos Problemas de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico 1: Quantidade de valores nulos por coluna\n",
    "plt.figure(figsize=(12, 6))\n",
    "null_values.plot(kind='bar', color='salmon')\n",
    "plt.title('Quantidade de Valores Nulos por Coluna')\n",
    "plt.ylabel('Quantidade de Valores Nulos')\n",
    "plt.xlabel('Colunas')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Gráfico 2: Distribuição dos Resultados Finais (ResultadoFinal_x)\n",
    "plt.figure(figsize=(8, 5))\n",
    "df_merged['ResultadoFinal_x'].fillna('Não informado').value_counts().plot(kind='bar', color='lightblue')\n",
    "plt.title('Distribuição dos Resultados Finais')\n",
    "plt.ylabel('Contagem')\n",
    "plt.xlabel('Resultado Final')\n",
    "plt.show()\n",
    "\n",
    "# Gráfico 3: Histograma da Distribuição de Faltas Anuais\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df_merged['QuantidadeFaltasAnual'].fillna(0), bins=30, kde=True, color='skyblue')\n",
    "plt.title('Distribuição da Quantidade de Faltas Anual')\n",
    "plt.xlabel('Faltas Anuais')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Quantidade de Valores Nulos por Coluna**: Número de valores ausentes em cada coluna, com destaque para colunas críticas como `QuantidadeFaltasAnual`, `ResultadoFinal_x`, e `AnoConclusao_y`, que apresentam muitos valores nulos.\n",
    "\n",
    "- `Distribuição dos Resultados Finais`: A maioria dos registros está classificada como \"Aprovado\", com uma grande parte de dados ausentes (preenchidos como \"Não informado\"), indicando um problema de variabilidade nos dados de desempenho.\n",
    "\n",
    "- `Distribuição da Quantidade de Faltas Anual`: Embora muitos dados estejam faltando, o histograma mostra que a maioria dos alunos não tem faltas registradas, o que levanta a questão sobre a completude dos dados de presença.\n",
    "\n",
    "## 3.7 Conclusão sobre a Viabilidade da Base de Dados\n",
    "\n",
    "Os dados parecem incompletos em várias áreas críticas, como o desempenho acadêmico e a presença dos alunos. Além disso, a maioria dos alunos está marcada como \"Aprovado\", o que pode refletir uma simplificação excessiva ou a ausência de registros de reprovação, distorcendo os resultados.\n",
    "\n",
    "Se os ajustes propostos forem implementados com sucesso (preenchimento de nulos, maior variabilidade nos resultados e dados completos), a base pode ser viável, mas limitada. Certas análises (como de presença e engajamento) ainda seriam prejudicadas sem dados adequados.\n",
    "\n",
    "Para a base compartilhada, a análise ser focada nos dados que estão mais completos, como análises específicas de desempenho com os alunos que possuem dados completos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Recomendações Finais\n",
    "Focar em Subconjuntos de Dados Completos: Muitas das análises viáveis dependem de filtrar o dataset para trabalhar apenas com os registros que possuem dados completos. Embora isso reduza o tamanho da amostra, ainda é possível gerar insights importantes.\n",
    "\n",
    "Documentar Limitações: Ao realizar qualquer uma dessas análises, é crucial documentar as limitações impostas pelos dados ausentes. Isso garante que as conclusões sejam interpretadas com cautela e que os resultados não sejam extrapolados indevidamente.\n",
    "\n",
    "Melhorar a Coleta de Dados Futuramente: Embora possamos realizar análises viáveis com o que temos, é fundamental melhorar a coleta de dados no futuro, especialmente em áreas críticas como desempenho acadêmico, frequência e registros socioeconômicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Tratamento da Base Municipios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_municipio = pd.read_csv('bases_e_documental/Base de dados - Passos Mágicos/Outras tabelas/TbMunicipio.csv', sep=',')\n",
    "df_municipio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_municipio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_municipio.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_municipio.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporta a base de municipios para csv\n",
    "# df_municipio.to_csv('bases_e_documental/df_municipio.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Gráficos de Apoio para o Relatório Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Análise de Desempenho dos Alunos com Dados Completos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar os dados para incluir apenas os registros com dados completos para ResultadoFinal_x, AnoConclusao_y, e QuantidadeFaltasAnual\n",
    "df_filtered = df_merged.dropna(subset=['ResultadoFinal_x', 'AnoConclusao_y', 'QuantidadeFaltasAnual'])\n",
    "\n",
    "# Contar o número de alunos aprovados (ResultadoFinal_x = 'Aprovado') e reprovados\n",
    "aprovados = df_filtered['ResultadoFinal_x'].value_counts()\n",
    "\n",
    "# Calcular a taxa de aprovação\n",
    "total_alunos = len(df_filtered)\n",
    "taxa_aprovacao = aprovados.get('A', 0) / total_alunos if total_alunos > 0 else 0\n",
    "\n",
    "# Exibir a taxa de aprovação e o total de alunos\n",
    "print(f\"Taxa de Aprovação: {taxa_aprovacao * 100}%\")\n",
    "print(f\"Total de Alunos com Dados Completos: {total_alunos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar gráfico de barras para visualização do desempenho\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='ResultadoFinal_x', data=df_filtered, palette='Blues')\n",
    "plt.title('Distribuição de Resultados Finais dos Alunos com Dados Completos')\n",
    "plt.xlabel('Resultado Final')\n",
    "plt.ylabel('Contagem de Alunos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Correlação entre Variáveis Socioeconômicas e Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar os dados para incluir registros com dados completos para ResultadoFinal_x e IdResponsavelFinanceiro\n",
    "df_filtered_socio = df_filtered.dropna(subset=['IdResponsavelFinanceiro'])\n",
    "\n",
    "# Converter a coluna de resultado final para uma variável binária (Aprovado = 1, Reprovado = 0)\n",
    "df_filtered_socio['Aprovado'] = df_filtered_socio['ResultadoFinal_x'].apply(lambda x: 1 if x == 'A' else 0)\n",
    "\n",
    "# Calcular a correlação entre IdResponsavelFinanceiro e o resultado acadêmico (Aprovado)\n",
    "correlacao_socio_desempenho = df_filtered_socio['IdResponsavelFinanceiro'].corr(df_filtered_socio['Aprovado'])\n",
    "\n",
    "# Exibir a correlação calculada\n",
    "print(f\"Correlação entre IdResponsavelFinanceiro e Aprovado: {correlacao_socio_desempenho}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Gerar um gráfico de dispersão para visualizar a relação entre IdResponsavelFinanceiro e Aprovado\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='IdResponsavelFinanceiro', y='Aprovado', data=df_filtered_socio, marker='x', color='blue')\n",
    "plt.title('Correlação entre Status Socioeconômico (IdResponsavelFinanceiro) e Desempenho Acadêmico')\n",
    "plt.xlabel('IdResponsavelFinanceiro')\n",
    "plt.ylabel('Aprovado (1 = Aprovado, 0 = Reprovado)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Análise de Engajamento e Faltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar os dados para incluir registros com dados completos para QuantidadeFaltasAnual e ResultadoFinal_x\n",
    "df_filtered_faltas = df_filtered.dropna(subset=['QuantidadeFaltasAnual', 'ResultadoFinal_x'])\n",
    "\n",
    "# Converter a coluna de resultado final para uma variável binária (Aprovado = 1, Reprovado = 0)\n",
    "df_filtered_faltas['Aprovado'] = df_filtered_faltas['ResultadoFinal_x'].apply(lambda x: 1 if x == 'A' else 0)\n",
    "\n",
    "# Criar um grupo de alunos com baixas faltas (menor que a mediana) e altas faltas (maior ou igual à mediana)\n",
    "mediana_faltas = df_filtered_faltas['QuantidadeFaltasAnual'].median()\n",
    "df_filtered_faltas['GrupoFaltas'] = df_filtered_faltas['QuantidadeFaltasAnual'].apply(lambda x: 'Baixas Faltas' if x < mediana_faltas else 'Altas Faltas')\n",
    "\n",
    "# Comparar o desempenho entre grupos de baixas e altas faltas\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='GrupoFaltas', y='Aprovado', data=df_filtered_faltas)\n",
    "plt.title('Comparação entre Faltas e Desempenho Acadêmico')\n",
    "plt.xlabel('Grupo de Faltas')\n",
    "plt.ylabel('Aprovado (1 = Aprovado, 0 = Reprovado)')\n",
    "plt.show()\n",
    "\n",
    "# Exibir a mediana das faltas para referência\n",
    "print(f\"Mediana de Faltas: {mediana_faltas}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Gráfico de comparação entre grupos de baixas e altas faltas no desempenho\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='GrupoFaltas', y='Aprovado', data=df_filtered_faltas)\n",
    "plt.title('Comparação entre Faltas e Desempenho Acadêmico')\n",
    "plt.xlabel('Grupo de Faltas')\n",
    "plt.ylabel('Aprovado (1 = Aprovado, 0 = Reprovado)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Evolução Temporal do Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar os dados para incluir registros com dados completos para ResultadoFinal_x e AnoConclusao_y\n",
    "df_filtered_ano = df_filtered.dropna(subset=['AnoConclusao_y', 'ResultadoFinal_x'])\n",
    "\n",
    "# Converter a coluna de resultado final para uma variável binária (Aprovado = 1, Reprovado = 0)\n",
    "df_filtered_ano['Aprovado'] = df_filtered_ano['ResultadoFinal_x'].apply(lambda x: 1 if x == 'A' else 0)\n",
    "\n",
    "# Agrupar os dados por ano de conclusão e calcular a taxa de aprovação\n",
    "taxa_aprovacao_por_ano = df_filtered_ano.groupby('AnoConclusao_y')['Aprovado'].mean()\n",
    "\n",
    "# Exibir as taxas de aprovação por ano\n",
    "print(taxa_aprovacao_por_ano)\n",
    "\n",
    "# Gerar um gráfico de linha para mostrar a evolução da taxa de aprovação ao longo dos anos\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=taxa_aprovacao_por_ano.index, y=taxa_aprovacao_por_ano.values, marker='o', color='blue')\n",
    "plt.title('Evolução da Taxa de Aprovação ao Longo dos Anos')\n",
    "plt.xlabel('Ano de Conclusão')\n",
    "plt.ylabel('Taxa de Aprovação')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Perfil dos Alunos Assistidos pela ONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar estatísticas descritivas básicas para o perfil dos alunos assistidos pela ONG\n",
    "perfil_alunos = df_merged[['IdAluno', 'IdResponsavelFinanceiro', 'QuantidadeFaltasAnual']].describe()\n",
    "\n",
    "# Exibir estatísticas descritivas do perfil dos alunos\n",
    "print(perfil_alunos)\n",
    "\n",
    "# Verificar a distribuição dos alunos por IdResponsavelFinanceiro (indicador socioeconômico)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_merged['IdResponsavelFinanceiro'].dropna(), bins=30, kde=False, color='lightblue')\n",
    "plt.title('Distribuição Socioeconômica dos Alunos (IdResponsavelFinanceiro)')\n",
    "plt.xlabel('IdResponsavelFinanceiro')\n",
    "plt.ylabel('Contagem de Alunos')\n",
    "plt.show()\n",
    "\n",
    "# Verificar a distribuição de faltas\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df_merged['QuantidadeFaltasAnual'].dropna(), bins=30, kde=True, color='lightgreen')\n",
    "plt.title('Distribuição de Faltas Anuais dos Alunos')\n",
    "plt.xlabel('Faltas Anuais')\n",
    "plt.ylabel('Contagem de Alunos')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
