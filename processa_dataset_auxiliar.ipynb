{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparkPostgres:\n",
    "    def __init__(self, spark, host, port, database, user, password):\n",
    "        self.spark = spark\n",
    "        self.url = f\"jdbc:postgresql://{host}:{port}/{database}\"\n",
    "        self.properties = {\n",
    "            \"user\": user,\n",
    "            \"password\": password,\n",
    "            \"driver\": \"org.postgresql.Driver\"\n",
    "        }\n",
    "    \n",
    "    def load_csv(self, file_path):\n",
    "        if os.path.exists(file_path):\n",
    "            df = self.spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"Error: O arquivo {file_path} n√£o existe.\")\n",
    "            return None\n",
    "    \n",
    "    def drop_and_create_table(self, schema, table, df):\n",
    "        drop_query = f\"DROP TABLE IF EXISTS {schema}.{table}\"\n",
    "        self.spark._jsparkSession \\\n",
    "            .sqlContext() \\\n",
    "            .executeUpdate(drop_query, self.properties)\n",
    "        \n",
    "        create_columns = \", \".join([f\"{self.clean_column_name(col_name)} STRING\" for col_name in df.columns])\n",
    "        create_query = f\"CREATE TABLE {schema}.{table} ({create_columns})\"\n",
    "        self.spark._jsparkSession \\\n",
    "            .sqlContext() \\\n",
    "            .executeUpdate(create_query, self.properties)\n",
    "    \n",
    "    def save_to_postgres(self, df, schema, table):\n",
    "        if df is not None:\n",
    "            self.drop_and_create_table(schema, table, df)\n",
    "            df = df.withColumn('dt_pst', current_date())\n",
    "            df.write.jdbc(\n",
    "                url=self.url,\n",
    "                table=f\"{schema}.{table}\",\n",
    "                mode=\"overwrite\",\n",
    "                properties=self.properties\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Error: DataFrame vazio para a tabela {schema}.{table}\")\n",
    "    \n",
    "    def run(self, base_path, mapping, schema):\n",
    "        for file_path, table_name in mapping.items():\n",
    "            self.process_file(base_path, file_path, table_name, schema)\n",
    "    \n",
    "    def clean_column_name(self, column_name):\n",
    "        column_name = column_name.lower().strip()\n",
    "        column_name = re.sub(r\"[^a-zA-Z0-9_]\", \"\", column_name)\n",
    "        column_name = re.sub(r\"\\s+\", \"_\", column_name)\n",
    "        return column_name\n",
    "    \n",
    "    def process_file(self, base_path, file_path, table_name, schema):\n",
    "        full_path = os.path.join(base_path, file_path)\n",
    "        \n",
    "        df = self.load_csv(full_path)\n",
    "        if df is not None:\n",
    "            for col_name in df.columns:\n",
    "                df = df.withColumnRenamed(col_name, self.clean_column_name(col_name))\n",
    "            \n",
    "            for col_name in df.columns:\n",
    "                df = df.withColumn(col_name, col(col_name).cast(\"string\"))\n",
    "            \n",
    "            self.save_to_postgres(df, schema, table_name)\n",
    "            print(f\"Tabela {table_name} processada com sucesso.\")\n",
    "        else:\n",
    "            print(f\"Erro ao processar o arquivo: {file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession.builder.appName(\"CSV to PostgreSQL\").getOrCreate()\n",
    "\n",
    "    host = os.getenv(\"DB_HOST\")\n",
    "    port = os.getenv(\"DB_PORT\")\n",
    "    database = os.getenv(\"DB_DATABASE\")\n",
    "    user = os.getenv(\"DB_USER\")\n",
    "    password = os.getenv(\"DB_PASSWORD\")\n",
    "    schema = os.getenv(\"DB_SCHEMA\")\n",
    "\n",
    "    base_path = \"source/\"\n",
    "\n",
    "    mapping = {\n",
    "        \"auxiliares/Originais anonimizados/TbSituacaoAlunoDisciplina.csv\": \"tb_sit_alun_disc\",\n",
    "        \"auxiliares/Originais anonimizados/TbTipoSituacaoAlunoDisciplina.csv\": \"tb_tip_sit_alun_disc\",\n",
    "        \"auxiliares/Outras tabelas/TbCentroResultado.csv\": \"tb_outr_tabel_cent_result\",\n",
    "        \"auxiliares/Outras tabelas/TbCursoFases.csv\": \"tb_outr_tabel_curs_fas\",\n",
    "        \"auxiliares/Outras tabelas/TbDisciplina.csv\": \"tb_outr_tabel_disc\",\n",
    "        \"auxiliares/Outras tabelas/TbFormaIngresso.csv\": \"tb_outr_tabel_form_ingr\",\n",
    "        \"auxiliares/Outras tabelas/TbFreqQuadroHorario.csv\": \"tb_outr_tabel_freq_quad_hor\",\n",
    "        \"auxiliares/Outras tabelas/TbGradeCurricular.csv\": \"tb_outr_tabel_grad_curr\",\n",
    "        \"auxiliares/Outras tabelas/TbMotivoInativacao.csv\": \"tb_outr_tabel_mot_inat\",\n",
    "        \"auxiliares/Outras tabelas/TbMunicipio.csv\": \"tb_outr_tabel_munic\",\n",
    "        \"auxiliares/Outras tabelas/TbPais.csv\": \"tb_outr_tabel_pais\",\n",
    "        \"auxiliares/Outras tabelas/TbPeriodo.csv\": \"tb_outr_tabel_periodo\",\n",
    "        \"auxiliares/Outras tabelas/TbTipoOcorrencia.csv\": \"tb_outr_tabel_tip_ocorr\",\n",
    "        \"auxiliares/TbAbatimento/Originais anonimizados/TbAbatimento.csv\": \"tb_abatim\",\n",
    "        \"auxiliares/TbAbatimento/Originais anonimizados/TbAbatimentoTipo.csv\": \"tb_abatim_tip\",\n",
    "        \"auxiliares/TbAluno/Originais anonimizados/TbAluno.csv\": \"tb_aluno\",\n",
    "        \"auxiliares/TbAluno/Originais anonimizados/TbAlunoObs.csv\": \"tb_aluno_obs\",\n",
    "        \"auxiliares/TbAluno/Originais anonimizados/TbAlunoProprioResponsavel.csv\": \"tb_aluno_prop_resp\",\n",
    "        \"auxiliares/TbAluno/Originais anonimizados/TbAlunoRotinaEducacaoInfantil.csv\": \"tb_aluno_rot_educ_inf\",\n",
    "        \"auxiliares/TbAluno/Originais anonimizados/TbAlunoTurma.csv\": \"tb_aluno_turma\",\n",
    "        \"auxiliares/TbAluno/Originais anonimizados/TbAlunoTurmaHistorico.csv\": \"tb_aluno_turma_hist\",\n",
    "        \"auxiliares/TbCampoDinamico/Originais anonimizados/TbCampoDinamico.csv\": \"tb_camp_dinam\",\n",
    "        \"auxiliares/TbCampoDinamico/Originais anonimizados/TbCampoDinamicoConjunto.csv\": \"tb_camp_dinam_conj\",\n",
    "        \"auxiliares/TbCampoDinamico/Originais anonimizados/TbCampoDinamicoConjuntoElemento.csv\": \"tb_camp_dinam_conj_elem\",\n",
    "        \"auxiliares/TbCaptacao/Originais anonimizados/TbCaptacaoCursoInteresse.csv\": \"tb_capt_curso_int\",\n",
    "        \"auxiliares/TbCaptacao/Originais anonimizados/TbCaptacaoMotivoDesistencia.csv\": \"tb_capt_mot_desist\",\n",
    "        \"auxiliares/TbCaptacao/Originais anonimizados/TbCaptacaoOrigemLead.csv\": \"tb_capt_orig_lead\",\n",
    "        \"auxiliares/TbCaptacao/Originais anonimizados/TbCaptacaoSituacaoLead.csv\": \"tb_capt_sit_lead\",\n",
    "        \"auxiliares/TbDiario/Originais anonimizados/TbDiario.csv\": \"tb_diario\",\n",
    "        \"auxiliares/TbDiario/Originais anonimizados/TbDiarioAluno.csv\": \"tb_diario_aluno\",\n",
    "        \"auxiliares/TbDiario/Originais anonimizados/TbDiarioAula.csv\": \"tb_diario_aula\",\n",
    "        \"auxiliares/TbDiario/Originais anonimizados/TbDiarioFrequencia.csv\": \"tb_diario_freq\",\n",
    "        \"auxiliares/TbFase/Originais anonimizados/TbFaseNota.csv\": \"tb_fase_nota\",\n",
    "        \"auxiliares/TbFase/Originais anonimizados/TbFaseNotaAluno.csv\": \"tb_fase_nota_aluno\",\n",
    "        \"auxiliares/TbFase/Originais anonimizados/TbFaseNotaDisciplinaTurma.csv\": \"tb_fase_nota_disc_turma\",\n",
    "        \"auxiliares/TbFase/Originais anonimizados/TbFaseNotaOrigemDestino.csv\": \"tb_fase_nota_orig_dest\",\n",
    "        \"auxiliares/TbHistorico/Originais anonimizados/TbHistorico.csv\": \"tb_hist\",\n",
    "        \"auxiliares/TbHistorico/Originais anonimizados/TbHistoricoNotas.csv\": \"tb_hist_nota\",\n",
    "        \"auxiliares/TbMeta/TbMeta.csv\": \"tb_meta\",\n",
    "        \"auxiliares/TbMeta/TbMetaConceito.csv\": \"tb_meta_conceito\",\n",
    "        \"auxiliares/TbMeta/TbMetaFaseNota.csv\": \"tb_meta_fase_nota\",\n",
    "        \"auxiliares/TbMeta/TbMetaFaseNotaAluno.csv\": \"tb_meta_fase_nota_aluno\",\n",
    "        \"auxiliares/TbMeta/TbMetaSituacaoAlunoDisciplina.csv\": \"tb_meta_sit_alun_disc\",\n",
    "        \"auxiliares/TbMeta/TbTipoMeta.csv\": \"tb_meta_tipo\",\n",
    "        \"auxiliares/TbProfessor/Originais anonimizados/TbProfessor.csv\": \"tb_professor\",\n",
    "        \"auxiliares/TbProfessor/Originais anonimizados/TbProfessorDisciplina.csv\": \"tb_prof_disc\",\n",
    "        \"auxiliares/TbProfessor/Originais anonimizados/TbProfessorHorario.csv\": \"tb_prof_horario\",\n",
    "        \"auxiliares/TbResponsavel/Originais anonimizados/TbResponsavel.csv\": \"tb_resp\",\n",
    "        \"auxiliares/TbResponsavel/Originais anonimizados/TbTipoResponsavel.csv\": \"tb_tipo_resp\",\n",
    "        \"auxiliares/TbResponsavel/Originais anonimizados/TbTipoVinculoAlunoResponsavel.csv\": \"tb_tipo_vinc_alun_resp\"\n",
    "    }\n",
    "\n",
    "\n",
    "    processar = SparkPostgres(spark, host, port, database, user, password)\n",
    "    processar.run(base_path, mapping, schema)\n",
    "\n",
    "    spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMTbf3rwvO+3iw/SZfpVjis",
   "collapsed_sections": [
    "jj1m78gyRuBO",
    "DdFcJHbkYY8J"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
